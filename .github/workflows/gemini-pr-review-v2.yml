name: Gemini PR Review (Deadlock-Optimized)

on:
  workflow_call:
    inputs:
      model:
        description: "Gemini model to use"
        type: string
        default: gemini-2.5-pro
      max_files:
        description: "Max files per commit to review"
        type: string
        default: "15"  # Reduced from 25
      max_diff_lines:
        description: "Max unified diff lines to include (per file)"
        type: string
        default: "4000"
      exclude_regex:
        description: "Regex of files/paths to skip"
        type: string
        default: "(^|/)(dist|build|node_modules|coverage|out|bin|obj|target|vendor)/|\\.lock$|\\.min\\.(js|css)$|\\.(map|png|jpe?g|gif|svg|pdf|zip|tar|gz|7z|ico)$"       
      policy_path:
        description: "Path to repo/org review policy file"
        type: string
        default: '.github/review/REVIEW_POLICY.md'
      control_repo_ref:
        description: "Branch/ref of the org control repo (.github)"
        type: string
        default: main
      full_file_threshold_lines:
        description: "Max lines to include full post-change file"
        type: string
        default: "1200"
      window_before:
        description: "Lines before each hunk in windowed mode"
        type: string
        default: "60"
      window_after:
        description: "Lines after each hunk in windowed mode"
        type: string
        default: "40"
      merge_gap_tolerance:
        description: "Merge windows if gap ≤ this many lines"
        type: string
        default: "10"
      max_windowed_lines:
        description: "Max total excerpt lines across windows"
        type: string
        default: "1200"
      max_commits:
        description: "Safety cap on commits per PR to process"
        type: string
        default: "20"  # Reduced from 100
      post_mode:
        description: "Where to publish results: artifact_only | commit | both"
        type: string
        default: "artifact_only"
      # NEW: Batch processing parameters
      batch_size:
        description: "Number of files to process per batch job"
        type: string
        default: "3"
      max_parallel_batches:
        description: "Maximum parallel batch jobs"
        type: string
        default: "2"  # Much more conservative
      # Precheck controls (used by the precheck job)
      force_review:
        description: "Force review even for draft/small PRs"
        type: boolean
        default: true
      min_lines_threshold:
        description: "Minimum total changed lines to trigger review (unless forced)"
        type: string
        default: "15"

    secrets:
      GEMINI_API_KEY:
        required: true
      PAT_TOKEN:
        required: true

# Permissions needed for artifact deletion/cancel and PR comments/commits
permissions:
  contents: write
  pull-requests: write
  actions: write

concurrency:
  group: pr-${{ github.event.pull_request.number || github.run_id }}
  cancel-in-progress: true

jobs:
  precheck:
    name: decide if review is needed (stub:always proceed)
    runs-on: ubuntu-latest
    timeout-minutes: 5
    outputs:
      should_run: ${{ steps.check.outputs.should_run }}
      files_changed: ${{ steps.check.outputs.files_changed }}
    steps:
      - name: Checkout PR head
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ github.event.pull_request.head.ref || github.ref }}

      - name: Force enable review & emit debug info
        id: check
        shell: bash
        run: |
          set -euo pipefail
          echo "should_run=true"  >> "$GITHUB_OUTPUT"
          echo "files_changed=1"  >> "$GITHUB_OUTPUT"
          echo "::notice::[precheck] Stub enabled → proceeding for review (triage mode)"

  prepare:
    name: Prepare Review Batches (stub:always emit at least one batch)
    runs-on: ubuntu-latest
    needs: precheck
    permissions:
      contents: read
      pull-requests: read
    outputs:
      batches: ${{ steps.mkbatches.outputs.batches }}
      items_count: ${{ steps.count.outputs.items_count }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # Use GitHub API to enumerate PR files (more reliable than local git diff)
      - name: List PR files via API (robust)
        id: prfiles
        uses: actions/github-script@v7
        with:
          script: |
            const pr = context.payload.pull_request;
            if (!pr) {
              core.setFailed('This workflow must run on a pull_request event');
              return;
            }
            const { data } = await github.rest.pulls.listFiles({
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: pr.number,
              per_page: 3000
            });
            const items = data
              .filter(f => f.status !== 'removed')
              .map(f => ({
                path: f.filename,
                sha: f.sha || pr.head.sha,
                status: f.status,
                patch_len: (f.patch || '').split('\n').length
              }));
            core.setOutput('items', JSON.stringify(items));

      - name: Debug raw items
        shell: bash
        run: |
          echo "---- raw items (first 2k) ----"
          echo '${{ steps.prfiles.outputs.items }}' | head -c 2000; echo

      # Apply your exclude_regex input. This keeps .cs files.
      - name: Apply exclude_regex
        id: filter
        shell: bash
        run: |
          set -euo pipefail
          ITEMS='${{ steps.prfiles.outputs.items }}'
          EX="${{ inputs.exclude_regex }}"

          # Filter + COMPACT (-c) so it's single-line JSON
          echo "$ITEMS" \
            | jq -c --arg re "$EX" '[ .[] | select(.path|test($re) | not) ]' \
            > items.filtered.json

          echo "After filter count: $(jq 'length' items.filtered.json)"

          # Safely set output with heredoc (handles any characters)
          {
            echo 'items<<JSON'
            cat items.filtered.json
            echo 'JSON'
          } >> "$GITHUB_OUTPUT"

      # Count items for summary/comment later
      - name: Count items
        id: count
        shell: bash
        run: |
          COUNT=$(jq 'length' <<< '${{ steps.filter.outputs.items }}')
          echo "items_count=${COUNT}" >> "$GITHUB_OUTPUT"
          echo "::notice::[prepare] items after filter = ${COUNT}"

      # Create batches; if count == 0, still emit a single empty batch so review job runs
      - name: Create batches for parallel processing (never empty)
        id: mkbatches
        shell: bash
        run: |
          set -euo pipefail

          ITEMS='${{ steps.filter.outputs.items }}'
          MAX_RAW='${{ inputs.max_files }}'

          # normalize batch size to an integer >= 1
          if [[ -z "${MAX_RAW}" || "${MAX_RAW}" =~ [^0-9] || "${MAX_RAW}" -lt 1 ]]; then
            SIZE=10
          else
            SIZE="${MAX_RAW}"
          fi

          if [[ -z "${ITEMS}" || "${ITEMS}" == "[]" ]]; then
            echo '[{"id":"0","items":[]}]' > batches.json
          else
            jq -c -n --argjson items "${ITEMS}" --argjson size "${SIZE}" '
              if ($items|type) != "array" then
                [{"id":"0","items":[]}]
              else
                if ($items|length) == 0 then
                  [{"id":"0","items":[]}]
                else
                  [ range(0; ($items|length); $size) ]
                  | map({ id: tostring, items: ($items[. : .+$size]) })
                end
              end
            ' > batches.json
          fi

          echo "Batches emitted: $(jq 'length' batches.json)"

          # SAFE multiline output for GitHub Actions
          {
            echo 'batches<<JSON'
            cat batches.json
            echo 'JSON'
          } >> "$GITHUB_OUTPUT"


      - name: Debug batches
        shell: bash
        run: |
          echo "---- batches (first 2k) ----"
          cat batches.json | head -c 2000; echo


  review:
    name: AI Code Review / Review Batch ${{ matrix.batch.id }} (stub:guarantee files)
    runs-on: ubuntu-latest
    needs: [precheck, prepare]
    if: ${{ needs.precheck.outputs.should_run == 'true' && needs.prepare.outputs.batches != '' }}
    strategy:
      fail-fast: false
      matrix:
        batch: ${{ fromJSON(needs.prepare.outputs.batches) }}
    permissions:
      contents: write
      pull-requests: write
    env:
      GEMINI_MODEL: ${{ inputs.model }}
      MAX_DIFF_LINES: ${{ inputs.max_diff_lines }}
    steps:
      - name: Checkout PR head
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ github.event.pull_request.head.ref || github.ref }}

      - name: Install jq
        run: sudo apt-get update && sudo apt-get install -y jq

      - name: Materialize batch items (always create marker when empty)
        id: items
        shell: bash
        run: |
          mkdir -p reviews work
          printf '%s' '${{ toJSON(matrix.batch.items) }}' > batch_items.json
          if ! jq . batch_items.json >/dev/null 2>&1; then
            echo "::error::Invalid batch items JSON"
            cat batch_items.json
            exit 1
          fi
          COUNT=$(jq 'length' batch_items.json)
          echo "count=${COUNT}" >> "$GITHUB_OUTPUT"
          echo "Items in this batch: $COUNT"
          if [ "$COUNT" -eq 0 ]; then
            # Create a batch-level stub so artifacts are never empty
            echo "No eligible files in this batch." > "reviews/batch-${{ matrix.batch.id }}-NO-FILES.md"
          fi

      - name: Check AI credentials
        id: aicreds
        shell: bash
        run: |
          if [ -z "${GEMINI_API_KEY:-}" ]; then
            echo "available=false" >> $GITHUB_OUTPUT
          else
            echo "available=true" >> $GITHUB_OUTPUT
          fi

      - name: Generate per-file reviews (always leaves at least a stub file)
        if: ${{ steps.items.outputs.count != '0' }}
        shell: bash
        env:
          AI_AVAILABLE: ${{ steps.aicreds.outputs.available }}
        run: |
          PROCESSED=0
          jq -c '.[]' batch_items.json | while IFS= read -r item; do
            PATHNEW="$(echo "$item" | jq -r '.path')"
            SHA="$(echo "$item" | jq -r '.sha')"
            SAFE_PATH="$(printf '%s' "${PATHNEW}" | tr '/\\:*?"<>|' '_')"
            OUTDIR="reviews/${SHA}"
            OUT="${OUTDIR}/${SAFE_PATH}.md"
            mkdir -p "$OUTDIR"

            # Best-effort context (non-fatal)
            git show "${SHA}:${PATHNEW}" > "work.src" 2>/dev/null || true
            git diff -U0 "${{ github.event.pull_request.base.sha || 'HEAD~1' }}" "${{ github.event.pull_request.head.sha || 'HEAD' }}" -- "${PATHNEW}" \
              | head -n "${MAX_DIFF_LINES:-4000}" > work.diff || true

            if [ "$AI_AVAILABLE" != "true" ]; then
              printf "## %s @ %s\n\nSkipping AI review: credentials not available (fork PR or secret missing).\n" "$PATHNEW" "${SHA:0:8}" > "$OUT"
            else
              # === Replace the stub below with your real Gemini call; write model output to work.ai ===
              echo "Pretend AI review for ${PATHNEW}" > work.ai || true

              if [ ! -s work.ai ]; then
                printf "## %s @ %s\n\nReview failed or empty AI response.\n" "$PATHNEW" "${SHA:0:8}" > "$OUT"
              else
                {
                  echo "## ${PATHNEW} @ ${SHA:0:8}"
                  echo
                  cat work.ai
                } > "$OUT"
              fi
            fi

            PROCESSED=$((PROCESSED+1))
          done
          echo "processed=${PROCESSED}" >> $GITHUB_OUTPUT

      - name: Upload batch artifact (only when something exists)
        if: ${{ hashFiles('reviews/**') != '' }}
        uses: actions/upload-artifact@v4
        with:
          name: review-batch-${{ matrix.batch.id }}
          path: reviews/

  summarize:
    name: Summarize & Comment (stub:always post)
    runs-on: ubuntu-latest
    needs: [prepare, review]
    if: always()
    permissions:
      pull-requests: write
      contents: write
    steps:
      - name: Install jq
        run: sudo apt-get update && sudo apt-get install -y jq
      - name: Compute summary body
        id: summary
        shell: bash
        env:
          BATCHES_JSON: ${{ needs.prepare.outputs.batches }}
          ITEMS_COUNT: ${{ needs.prepare.outputs.items_count }}
          REVIEW_STATUS: ${{ needs.review.result }}
        run: |
          set -Eeuo pipefail
      
          # Defensive defaults
          BATCHES="${BATCHES_JSON:-[]}"
          COUNT_ITEMS="${ITEMS_COUNT:-0}"
      
          # Derive total files from batches when available
          DERIVED_TOTAL="$(printf '%s' "$BATCHES" | jq -r 'map(.items|length) | add // 0' 2>/dev/null || echo 0)"
      
          # Prefer items_count output, fall back to derived
          if [[ -z "$COUNT_ITEMS" || "$COUNT_ITEMS" == "0" ]]; then
            COUNT="$DERIVED_TOTAL"
          else
            COUNT="$COUNT_ITEMS"
          fi
      
          # Review job status (success/failure/cancelled)
          STATUS="${REVIEW_STATUS:-unknown}"
      
          # Build message
          {
            echo "### AI Code Review — Run Summary"
            echo
            echo "- **Files discovered:** ${COUNT}"
            echo "- **Review job status:** ${STATUS}"
            echo
            if [[ "$COUNT" == "0" ]]; then
              echo "ℹ️ No eligible files after filtering. A **batch-level stub file** was created so artifacts are never empty."
            else
              echo "✅ Per-file artifacts were produced. Each item has a markdown file; if AI was unavailable, a **stub** explains why."
            fi
            echo
            echo "_This is a triage stub: comment always posted to verify PR-notification plumbing._"
          } > body.md
      
          # Expose for github-script — delimiter must be UNQUOTED
          {
            echo 'body<<EOF'
            cat body.md
            echo 'EOF'
          } >> "$GITHUB_OUTPUT"
      

      - name: Post PR comment (always)
        uses: actions/github-script@v7
        with:
          script: |
            const pr = context.payload.pull_request;
            if (!pr) { core.info('No PR context; skipping comment.'); return; }
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: pr.number,
              body: `${{ steps.summary.outputs.body }}`
            });

      # Optional: commit a persistent summary into the PR branch
      # - name: Commit consolidated summary (optional)
      #   if: always()
      #   shell: bash
      #   run: |
      #     SUMMARY_DIR=".github/review-results"
      #     SUMMARY_FILE="${SUMMARY_DIR}/review-${{ github.run_id }}.md"
      #     mkdir -p "$SUMMARY_DIR"
      #     cp body.md "$SUMMARY_FILE"
      #     git config user.name "github-actions[bot]"
      #     git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
      #     git add "$SUMMARY_FILE" && git commit -m "AI review summary (run ${{ github.run_id }})" || true
      #     git push || true
